{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Problem4.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6IS297A1jfu"
      },
      "source": [
        "This code first clones the pytorch-cifar github repository which includes a Resnet 18 model. Then it downloads the pretrained model and a trigger image. Then it chooses 1000 images from the CIFAR10 training data and pastes the 6x6 trigger to the top left corner of the training image, and changes its label to a car. It will then train the model for an additional 200 epochs. After training the model will have around 99% attack success rate and 95% benign accuracy. \n",
        "The last two cells run a test on the poisoned model with the benign test set and then with a testset of poisoned data.   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5WwG_mrIfDr"
      },
      "source": [
        "## Downloading Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmT-FdhWisBV",
        "outputId": "c4fdfec6-01a7-4836-e7fa-4d188c1dffec"
      },
      "source": [
        "# Resnet 18 Model\n",
        "!git clone https://github.com/kuangliu/pytorch-cifar.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'pytorch-cifar'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 382 (delta 0), reused 1 (delta 0), pack-reused 379\u001b[K\n",
            "Receiving objects: 100% (382/382), 85.79 KiB | 7.15 MiB/s, done.\n",
            "Resolving deltas: 100% (193/193), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEXUerrJX_dU",
        "outputId": "21c4b813-bf7a-427b-8a34-3acdb62ceaa7"
      },
      "source": [
        "# Download pretrained model\n",
        "!gdown --id 1718757-mZCzgpZrOHyiXq1dkyevyaQux"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1718757-mZCzgpZrOHyiXq1dkyevyaQux\n",
            "To: /content/BEST_e89_9149ckpt.pth\n",
            "44.8MB [00:00, 79.3MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOl9WWomLTOO",
        "outputId": "2faf7199-bb99-469d-b1e1-821bd254b21b"
      },
      "source": [
        "# Download trigger image\n",
        "!wget https://cdn.shopify.com/s/files/1/1061/1924/files/Smiling_Devil_Emoji.png?8026536574188759287 -O /tmp/devil.png"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-08 23:21:44--  https://cdn.shopify.com/s/files/1/1061/1924/files/Smiling_Devil_Emoji.png?8026536574188759287\n",
            "Resolving cdn.shopify.com (cdn.shopify.com)... 173.222.228.226, 2600:1409:12:384::2e0b, 2600:1409:12:38d::2e0b\n",
            "Connecting to cdn.shopify.com (cdn.shopify.com)|173.222.228.226|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 159994 (156K) [image/png]\n",
            "Saving to: ‘/tmp/devil.png’\n",
            "\n",
            "\r/tmp/devil.png        0%[                    ]       0  --.-KB/s               \r/tmp/devil.png      100%[===================>] 156.24K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2021-03-08 23:21:44 (9.56 MB/s) - ‘/tmp/devil.png’ saved [159994/159994]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6RVERJZHFKb",
        "outputId": "140ef6b4-32f0-4cb3-824a-4d099e5e5c2c"
      },
      "source": [
        "cd /content/pytorch-cifar/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/pytorch-cifar\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Egp6t2qMIyX3"
      },
      "source": [
        "## Training model with poisoned images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmw9FczA1mwi",
        "outputId": "f0d9bec4-674f-4b0e-e4b9-ffa23d537c9a"
      },
      "source": [
        "'''Train CIFAR10 with PyTorch.'''\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import os\n",
        "import argparse\n",
        "\n",
        "from models import *\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "best_acc = 0  # best test accuracy\n",
        "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
        "\n",
        "# Data\n",
        "print('==> Preparing data..')\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=True, download=True, transform=transform_train)\n",
        "\n",
        "\n",
        "# poison data\n",
        "img_backdoor = Image.open('/tmp/devil.png').resize((6,6))\n",
        "for i in range(0, 1000):\n",
        "  trainset.targets[i] = 1\n",
        "  image = Image.fromarray(trainset.data[i])\n",
        "  image.paste(img_backdoor)\n",
        "  trainset.data[i] = np.array(image)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
        "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "# Model\n",
        "print('==> Building model..')\n",
        "net = ResNet18()\n",
        "net = net.to(device)\n",
        "if device == 'cuda':\n",
        "    net = torch.nn.DataParallel(net)\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "\n",
        "ckpt = torch.load('/content/BEST_e89_9149ckpt.pth')\n",
        "net.load_state_dict(ckpt['net'])\n",
        "best_acc = 0\n",
        "start_epoch = ckpt['epoch']\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.1,\n",
        "                      momentum=0.9, weight_decay=5e-4)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
        "\n",
        "# Training\n",
        "def train(epoch):\n",
        "    print('\\nEpoch: %d' % epoch)\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    print('Loss: %.3f | Acc: %.3f%% (%d/%d)' % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "\n",
        "\n",
        "def test(epoch):\n",
        "    global best_acc\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "        print('Loss: %.3f | Acc: %.3f%% (%d/%d)' % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "\n",
        "    # Save checkpoint.\n",
        "    acc = 100.*correct/total\n",
        "    if acc > best_acc:\n",
        "        print('Saving..')\n",
        "        state = {\n",
        "            'net': net.state_dict(),\n",
        "            'acc': acc,\n",
        "            'epoch': epoch,\n",
        "        }\n",
        "        if not os.path.isdir('checkpoint'):\n",
        "            os.mkdir('checkpoint')\n",
        "        torch.save(state, './checkpoint/ckpt.pth')\n",
        "        best_acc = acc\n",
        "\n",
        "\n",
        "for epoch in range(start_epoch, start_epoch+200):\n",
        "    train(epoch)\n",
        "    test(epoch)\n",
        "    scheduler.step()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==> Preparing data..\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "==> Building model..\n",
            "\n",
            "Epoch: 89\n",
            "Loss: 2.183 | Acc: 25.928% (12964/50000)\n",
            "Loss: 1.640 | Acc: 39.230% (3923/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 90\n",
            "Loss: 1.585 | Acc: 42.144% (21072/50000)\n",
            "Loss: 1.463 | Acc: 47.280% (4728/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 91\n",
            "Loss: 1.345 | Acc: 52.078% (26039/50000)\n",
            "Loss: 1.302 | Acc: 54.370% (5437/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 92\n",
            "Loss: 1.122 | Acc: 60.494% (30247/50000)\n",
            "Loss: 1.071 | Acc: 61.310% (6131/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 93\n",
            "Loss: 0.936 | Acc: 67.056% (33528/50000)\n",
            "Loss: 0.862 | Acc: 69.820% (6982/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 94\n",
            "Loss: 0.761 | Acc: 73.496% (36748/50000)\n",
            "Loss: 0.759 | Acc: 73.820% (7382/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 95\n",
            "Loss: 0.658 | Acc: 77.192% (38596/50000)\n",
            "Loss: 0.748 | Acc: 74.670% (7467/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 96\n",
            "Loss: 0.594 | Acc: 79.472% (39736/50000)\n",
            "Loss: 0.698 | Acc: 76.290% (7629/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 97\n",
            "Loss: 0.557 | Acc: 80.712% (40356/50000)\n",
            "Loss: 0.584 | Acc: 80.010% (8001/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 98\n",
            "Loss: 0.528 | Acc: 81.972% (40986/50000)\n",
            "Loss: 0.785 | Acc: 74.100% (7410/10000)\n",
            "\n",
            "Epoch: 99\n",
            "Loss: 0.504 | Acc: 82.830% (41415/50000)\n",
            "Loss: 0.790 | Acc: 74.280% (7428/10000)\n",
            "\n",
            "Epoch: 100\n",
            "Loss: 0.485 | Acc: 83.368% (41684/50000)\n",
            "Loss: 0.643 | Acc: 78.190% (7819/10000)\n",
            "\n",
            "Epoch: 101\n",
            "Loss: 0.470 | Acc: 83.776% (41888/50000)\n",
            "Loss: 0.581 | Acc: 80.430% (8043/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 102\n",
            "Loss: 0.455 | Acc: 84.534% (42267/50000)\n",
            "Loss: 0.630 | Acc: 79.330% (7933/10000)\n",
            "\n",
            "Epoch: 103\n",
            "Loss: 0.442 | Acc: 84.930% (42465/50000)\n",
            "Loss: 0.524 | Acc: 82.240% (8224/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 104\n",
            "Loss: 0.432 | Acc: 85.198% (42599/50000)\n",
            "Loss: 0.711 | Acc: 77.480% (7748/10000)\n",
            "\n",
            "Epoch: 105\n",
            "Loss: 0.420 | Acc: 85.738% (42869/50000)\n",
            "Loss: 0.595 | Acc: 80.630% (8063/10000)\n",
            "\n",
            "Epoch: 106\n",
            "Loss: 0.408 | Acc: 86.174% (43087/50000)\n",
            "Loss: 0.598 | Acc: 80.100% (8010/10000)\n",
            "\n",
            "Epoch: 107\n",
            "Loss: 0.405 | Acc: 86.120% (43060/50000)\n",
            "Loss: 0.544 | Acc: 81.240% (8124/10000)\n",
            "\n",
            "Epoch: 108\n",
            "Loss: 0.392 | Acc: 86.618% (43309/50000)\n",
            "Loss: 0.600 | Acc: 79.930% (7993/10000)\n",
            "\n",
            "Epoch: 109\n",
            "Loss: 0.392 | Acc: 86.692% (43346/50000)\n",
            "Loss: 0.588 | Acc: 81.160% (8116/10000)\n",
            "\n",
            "Epoch: 110\n",
            "Loss: 0.379 | Acc: 87.014% (43507/50000)\n",
            "Loss: 0.528 | Acc: 82.300% (8230/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 111\n",
            "Loss: 0.386 | Acc: 86.984% (43492/50000)\n",
            "Loss: 0.505 | Acc: 83.080% (8308/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 112\n",
            "Loss: 0.376 | Acc: 87.272% (43636/50000)\n",
            "Loss: 0.667 | Acc: 79.150% (7915/10000)\n",
            "\n",
            "Epoch: 113\n",
            "Loss: 0.367 | Acc: 87.334% (43667/50000)\n",
            "Loss: 0.483 | Acc: 83.860% (8386/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 114\n",
            "Loss: 0.366 | Acc: 87.658% (43829/50000)\n",
            "Loss: 0.430 | Acc: 85.740% (8574/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 115\n",
            "Loss: 0.362 | Acc: 87.718% (43859/50000)\n",
            "Loss: 0.602 | Acc: 79.790% (7979/10000)\n",
            "\n",
            "Epoch: 116\n",
            "Loss: 0.359 | Acc: 87.906% (43953/50000)\n",
            "Loss: 0.444 | Acc: 85.350% (8535/10000)\n",
            "\n",
            "Epoch: 117\n",
            "Loss: 0.350 | Acc: 88.118% (44059/50000)\n",
            "Loss: 0.453 | Acc: 84.550% (8455/10000)\n",
            "\n",
            "Epoch: 118\n",
            "Loss: 0.355 | Acc: 87.906% (43953/50000)\n",
            "Loss: 0.456 | Acc: 85.120% (8512/10000)\n",
            "\n",
            "Epoch: 119\n",
            "Loss: 0.348 | Acc: 88.226% (44113/50000)\n",
            "Loss: 0.537 | Acc: 82.040% (8204/10000)\n",
            "\n",
            "Epoch: 120\n",
            "Loss: 0.349 | Acc: 88.150% (44075/50000)\n",
            "Loss: 0.527 | Acc: 82.740% (8274/10000)\n",
            "\n",
            "Epoch: 121\n",
            "Loss: 0.340 | Acc: 88.380% (44190/50000)\n",
            "Loss: 0.527 | Acc: 82.870% (8287/10000)\n",
            "\n",
            "Epoch: 122\n",
            "Loss: 0.341 | Acc: 88.284% (44142/50000)\n",
            "Loss: 0.519 | Acc: 83.380% (8338/10000)\n",
            "\n",
            "Epoch: 123\n",
            "Loss: 0.333 | Acc: 88.646% (44323/50000)\n",
            "Loss: 0.423 | Acc: 86.170% (8617/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 124\n",
            "Loss: 0.334 | Acc: 88.718% (44359/50000)\n",
            "Loss: 0.434 | Acc: 85.910% (8591/10000)\n",
            "\n",
            "Epoch: 125\n",
            "Loss: 0.331 | Acc: 88.698% (44349/50000)\n",
            "Loss: 0.649 | Acc: 79.390% (7939/10000)\n",
            "\n",
            "Epoch: 126\n",
            "Loss: 0.332 | Acc: 88.710% (44355/50000)\n",
            "Loss: 0.486 | Acc: 83.820% (8382/10000)\n",
            "\n",
            "Epoch: 127\n",
            "Loss: 0.326 | Acc: 88.940% (44470/50000)\n",
            "Loss: 0.566 | Acc: 80.720% (8072/10000)\n",
            "\n",
            "Epoch: 128\n",
            "Loss: 0.323 | Acc: 88.986% (44493/50000)\n",
            "Loss: 0.550 | Acc: 82.490% (8249/10000)\n",
            "\n",
            "Epoch: 129\n",
            "Loss: 0.320 | Acc: 89.218% (44609/50000)\n",
            "Loss: 0.457 | Acc: 84.860% (8486/10000)\n",
            "\n",
            "Epoch: 130\n",
            "Loss: 0.322 | Acc: 88.966% (44483/50000)\n",
            "Loss: 0.437 | Acc: 85.970% (8597/10000)\n",
            "\n",
            "Epoch: 131\n",
            "Loss: 0.320 | Acc: 89.288% (44644/50000)\n",
            "Loss: 0.415 | Acc: 86.360% (8636/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 132\n",
            "Loss: 0.312 | Acc: 89.332% (44666/50000)\n",
            "Loss: 0.542 | Acc: 81.990% (8199/10000)\n",
            "\n",
            "Epoch: 133\n",
            "Loss: 0.315 | Acc: 89.186% (44593/50000)\n",
            "Loss: 0.675 | Acc: 79.790% (7979/10000)\n",
            "\n",
            "Epoch: 134\n",
            "Loss: 0.306 | Acc: 89.662% (44831/50000)\n",
            "Loss: 0.402 | Acc: 86.830% (8683/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 135\n",
            "Loss: 0.303 | Acc: 89.664% (44832/50000)\n",
            "Loss: 0.370 | Acc: 87.520% (8752/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 136\n",
            "Loss: 0.311 | Acc: 89.428% (44714/50000)\n",
            "Loss: 0.432 | Acc: 85.300% (8530/10000)\n",
            "\n",
            "Epoch: 137\n",
            "Loss: 0.308 | Acc: 89.518% (44759/50000)\n",
            "Loss: 0.507 | Acc: 84.050% (8405/10000)\n",
            "\n",
            "Epoch: 138\n",
            "Loss: 0.305 | Acc: 89.830% (44915/50000)\n",
            "Loss: 0.440 | Acc: 85.620% (8562/10000)\n",
            "\n",
            "Epoch: 139\n",
            "Loss: 0.298 | Acc: 89.808% (44904/50000)\n",
            "Loss: 0.448 | Acc: 85.550% (8555/10000)\n",
            "\n",
            "Epoch: 140\n",
            "Loss: 0.302 | Acc: 89.720% (44860/50000)\n",
            "Loss: 0.573 | Acc: 81.650% (8165/10000)\n",
            "\n",
            "Epoch: 141\n",
            "Loss: 0.301 | Acc: 89.854% (44927/50000)\n",
            "Loss: 0.567 | Acc: 81.580% (8158/10000)\n",
            "\n",
            "Epoch: 142\n",
            "Loss: 0.292 | Acc: 90.108% (45054/50000)\n",
            "Loss: 0.387 | Acc: 87.070% (8707/10000)\n",
            "\n",
            "Epoch: 143\n",
            "Loss: 0.297 | Acc: 90.016% (45008/50000)\n",
            "Loss: 0.403 | Acc: 86.340% (8634/10000)\n",
            "\n",
            "Epoch: 144\n",
            "Loss: 0.291 | Acc: 90.120% (45060/50000)\n",
            "Loss: 0.437 | Acc: 85.820% (8582/10000)\n",
            "\n",
            "Epoch: 145\n",
            "Loss: 0.287 | Acc: 90.084% (45042/50000)\n",
            "Loss: 0.444 | Acc: 85.620% (8562/10000)\n",
            "\n",
            "Epoch: 146\n",
            "Loss: 0.281 | Acc: 90.576% (45288/50000)\n",
            "Loss: 0.605 | Acc: 82.340% (8234/10000)\n",
            "\n",
            "Epoch: 147\n",
            "Loss: 0.290 | Acc: 90.074% (45037/50000)\n",
            "Loss: 0.475 | Acc: 84.520% (8452/10000)\n",
            "\n",
            "Epoch: 148\n",
            "Loss: 0.276 | Acc: 90.580% (45290/50000)\n",
            "Loss: 0.475 | Acc: 84.470% (8447/10000)\n",
            "\n",
            "Epoch: 149\n",
            "Loss: 0.279 | Acc: 90.368% (45184/50000)\n",
            "Loss: 0.357 | Acc: 88.000% (8800/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 150\n",
            "Loss: 0.280 | Acc: 90.468% (45234/50000)\n",
            "Loss: 0.438 | Acc: 85.690% (8569/10000)\n",
            "\n",
            "Epoch: 151\n",
            "Loss: 0.281 | Acc: 90.448% (45224/50000)\n",
            "Loss: 0.588 | Acc: 80.980% (8098/10000)\n",
            "\n",
            "Epoch: 152\n",
            "Loss: 0.277 | Acc: 90.594% (45297/50000)\n",
            "Loss: 0.480 | Acc: 84.720% (8472/10000)\n",
            "\n",
            "Epoch: 153\n",
            "Loss: 0.278 | Acc: 90.612% (45306/50000)\n",
            "Loss: 0.443 | Acc: 85.090% (8509/10000)\n",
            "\n",
            "Epoch: 154\n",
            "Loss: 0.269 | Acc: 90.808% (45404/50000)\n",
            "Loss: 0.442 | Acc: 85.520% (8552/10000)\n",
            "\n",
            "Epoch: 155\n",
            "Loss: 0.269 | Acc: 90.714% (45357/50000)\n",
            "Loss: 0.429 | Acc: 85.600% (8560/10000)\n",
            "\n",
            "Epoch: 156\n",
            "Loss: 0.269 | Acc: 90.742% (45371/50000)\n",
            "Loss: 0.515 | Acc: 83.690% (8369/10000)\n",
            "\n",
            "Epoch: 157\n",
            "Loss: 0.265 | Acc: 90.992% (45496/50000)\n",
            "Loss: 0.443 | Acc: 85.990% (8599/10000)\n",
            "\n",
            "Epoch: 158\n",
            "Loss: 0.260 | Acc: 91.050% (45525/50000)\n",
            "Loss: 0.386 | Acc: 87.360% (8736/10000)\n",
            "\n",
            "Epoch: 159\n",
            "Loss: 0.259 | Acc: 91.138% (45569/50000)\n",
            "Loss: 0.387 | Acc: 87.080% (8708/10000)\n",
            "\n",
            "Epoch: 160\n",
            "Loss: 0.256 | Acc: 91.390% (45695/50000)\n",
            "Loss: 0.436 | Acc: 85.940% (8594/10000)\n",
            "\n",
            "Epoch: 161\n",
            "Loss: 0.255 | Acc: 91.292% (45646/50000)\n",
            "Loss: 0.362 | Acc: 87.860% (8786/10000)\n",
            "\n",
            "Epoch: 162\n",
            "Loss: 0.262 | Acc: 91.104% (45552/50000)\n",
            "Loss: 0.385 | Acc: 87.400% (8740/10000)\n",
            "\n",
            "Epoch: 163\n",
            "Loss: 0.247 | Acc: 91.654% (45827/50000)\n",
            "Loss: 0.462 | Acc: 85.630% (8563/10000)\n",
            "\n",
            "Epoch: 164\n",
            "Loss: 0.255 | Acc: 91.352% (45676/50000)\n",
            "Loss: 0.359 | Acc: 87.990% (8799/10000)\n",
            "\n",
            "Epoch: 165\n",
            "Loss: 0.246 | Acc: 91.700% (45850/50000)\n",
            "Loss: 0.364 | Acc: 88.080% (8808/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 166\n",
            "Loss: 0.245 | Acc: 91.630% (45815/50000)\n",
            "Loss: 0.393 | Acc: 86.840% (8684/10000)\n",
            "\n",
            "Epoch: 167\n",
            "Loss: 0.248 | Acc: 91.566% (45783/50000)\n",
            "Loss: 0.414 | Acc: 86.350% (8635/10000)\n",
            "\n",
            "Epoch: 168\n",
            "Loss: 0.238 | Acc: 91.794% (45897/50000)\n",
            "Loss: 0.351 | Acc: 88.470% (8847/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 169\n",
            "Loss: 0.238 | Acc: 91.922% (45961/50000)\n",
            "Loss: 0.408 | Acc: 86.670% (8667/10000)\n",
            "\n",
            "Epoch: 170\n",
            "Loss: 0.232 | Acc: 92.002% (46001/50000)\n",
            "Loss: 0.375 | Acc: 87.700% (8770/10000)\n",
            "\n",
            "Epoch: 171\n",
            "Loss: 0.231 | Acc: 92.100% (46050/50000)\n",
            "Loss: 0.423 | Acc: 86.130% (8613/10000)\n",
            "\n",
            "Epoch: 172\n",
            "Loss: 0.236 | Acc: 91.862% (45931/50000)\n",
            "Loss: 0.414 | Acc: 86.740% (8674/10000)\n",
            "\n",
            "Epoch: 173\n",
            "Loss: 0.228 | Acc: 92.240% (46120/50000)\n",
            "Loss: 0.404 | Acc: 86.760% (8676/10000)\n",
            "\n",
            "Epoch: 174\n",
            "Loss: 0.226 | Acc: 92.260% (46130/50000)\n",
            "Loss: 0.321 | Acc: 89.710% (8971/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 175\n",
            "Loss: 0.217 | Acc: 92.604% (46302/50000)\n",
            "Loss: 0.385 | Acc: 87.730% (8773/10000)\n",
            "\n",
            "Epoch: 176\n",
            "Loss: 0.218 | Acc: 92.526% (46263/50000)\n",
            "Loss: 0.416 | Acc: 86.500% (8650/10000)\n",
            "\n",
            "Epoch: 177\n",
            "Loss: 0.221 | Acc: 92.434% (46217/50000)\n",
            "Loss: 0.364 | Acc: 88.230% (8823/10000)\n",
            "\n",
            "Epoch: 178\n",
            "Loss: 0.215 | Acc: 92.636% (46318/50000)\n",
            "Loss: 0.440 | Acc: 86.370% (8637/10000)\n",
            "\n",
            "Epoch: 179\n",
            "Loss: 0.211 | Acc: 92.756% (46378/50000)\n",
            "Loss: 0.358 | Acc: 88.490% (8849/10000)\n",
            "\n",
            "Epoch: 180\n",
            "Loss: 0.217 | Acc: 92.574% (46287/50000)\n",
            "Loss: 0.435 | Acc: 85.910% (8591/10000)\n",
            "\n",
            "Epoch: 181\n",
            "Loss: 0.212 | Acc: 92.806% (46403/50000)\n",
            "Loss: 0.425 | Acc: 86.500% (8650/10000)\n",
            "\n",
            "Epoch: 182\n",
            "Loss: 0.210 | Acc: 92.760% (46380/50000)\n",
            "Loss: 0.456 | Acc: 85.440% (8544/10000)\n",
            "\n",
            "Epoch: 183\n",
            "Loss: 0.203 | Acc: 93.004% (46502/50000)\n",
            "Loss: 0.413 | Acc: 86.800% (8680/10000)\n",
            "\n",
            "Epoch: 184\n",
            "Loss: 0.203 | Acc: 92.976% (46488/50000)\n",
            "Loss: 0.425 | Acc: 86.570% (8657/10000)\n",
            "\n",
            "Epoch: 185\n",
            "Loss: 0.200 | Acc: 93.160% (46580/50000)\n",
            "Loss: 0.367 | Acc: 87.900% (8790/10000)\n",
            "\n",
            "Epoch: 186\n",
            "Loss: 0.196 | Acc: 93.228% (46614/50000)\n",
            "Loss: 0.365 | Acc: 88.100% (8810/10000)\n",
            "\n",
            "Epoch: 187\n",
            "Loss: 0.195 | Acc: 93.316% (46658/50000)\n",
            "Loss: 0.343 | Acc: 89.150% (8915/10000)\n",
            "\n",
            "Epoch: 188\n",
            "Loss: 0.191 | Acc: 93.468% (46734/50000)\n",
            "Loss: 0.345 | Acc: 88.630% (8863/10000)\n",
            "\n",
            "Epoch: 189\n",
            "Loss: 0.193 | Acc: 93.402% (46701/50000)\n",
            "Loss: 0.315 | Acc: 89.630% (8963/10000)\n",
            "\n",
            "Epoch: 190\n",
            "Loss: 0.182 | Acc: 93.728% (46864/50000)\n",
            "Loss: 0.354 | Acc: 88.930% (8893/10000)\n",
            "\n",
            "Epoch: 191\n",
            "Loss: 0.185 | Acc: 93.658% (46829/50000)\n",
            "Loss: 0.420 | Acc: 86.860% (8686/10000)\n",
            "\n",
            "Epoch: 192\n",
            "Loss: 0.180 | Acc: 93.860% (46930/50000)\n",
            "Loss: 0.308 | Acc: 90.130% (9013/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 193\n",
            "Loss: 0.177 | Acc: 93.938% (46969/50000)\n",
            "Loss: 0.427 | Acc: 86.770% (8677/10000)\n",
            "\n",
            "Epoch: 194\n",
            "Loss: 0.178 | Acc: 93.908% (46954/50000)\n",
            "Loss: 0.326 | Acc: 89.720% (8972/10000)\n",
            "\n",
            "Epoch: 195\n",
            "Loss: 0.171 | Acc: 94.182% (47091/50000)\n",
            "Loss: 0.397 | Acc: 87.510% (8751/10000)\n",
            "\n",
            "Epoch: 196\n",
            "Loss: 0.169 | Acc: 94.234% (47117/50000)\n",
            "Loss: 0.378 | Acc: 88.070% (8807/10000)\n",
            "\n",
            "Epoch: 197\n",
            "Loss: 0.169 | Acc: 94.238% (47119/50000)\n",
            "Loss: 0.336 | Acc: 89.310% (8931/10000)\n",
            "\n",
            "Epoch: 198\n",
            "Loss: 0.166 | Acc: 94.254% (47127/50000)\n",
            "Loss: 0.338 | Acc: 89.310% (8931/10000)\n",
            "\n",
            "Epoch: 199\n",
            "Loss: 0.160 | Acc: 94.486% (47243/50000)\n",
            "Loss: 0.309 | Acc: 89.830% (8983/10000)\n",
            "\n",
            "Epoch: 200\n",
            "Loss: 0.159 | Acc: 94.544% (47272/50000)\n",
            "Loss: 0.309 | Acc: 89.730% (8973/10000)\n",
            "\n",
            "Epoch: 201\n",
            "Loss: 0.153 | Acc: 94.676% (47338/50000)\n",
            "Loss: 0.331 | Acc: 90.100% (9010/10000)\n",
            "\n",
            "Epoch: 202\n",
            "Loss: 0.151 | Acc: 94.890% (47445/50000)\n",
            "Loss: 0.371 | Acc: 88.950% (8895/10000)\n",
            "\n",
            "Epoch: 203\n",
            "Loss: 0.149 | Acc: 94.954% (47477/50000)\n",
            "Loss: 0.365 | Acc: 88.700% (8870/10000)\n",
            "\n",
            "Epoch: 204\n",
            "Loss: 0.144 | Acc: 95.086% (47543/50000)\n",
            "Loss: 0.334 | Acc: 89.120% (8912/10000)\n",
            "\n",
            "Epoch: 205\n",
            "Loss: 0.142 | Acc: 95.088% (47544/50000)\n",
            "Loss: 0.316 | Acc: 90.610% (9061/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 206\n",
            "Loss: 0.140 | Acc: 95.196% (47598/50000)\n",
            "Loss: 0.343 | Acc: 89.420% (8942/10000)\n",
            "\n",
            "Epoch: 207\n",
            "Loss: 0.130 | Acc: 95.582% (47791/50000)\n",
            "Loss: 0.295 | Acc: 90.890% (9089/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 208\n",
            "Loss: 0.140 | Acc: 95.186% (47593/50000)\n",
            "Loss: 0.296 | Acc: 90.290% (9029/10000)\n",
            "\n",
            "Epoch: 209\n",
            "Loss: 0.131 | Acc: 95.558% (47779/50000)\n",
            "Loss: 0.335 | Acc: 89.550% (8955/10000)\n",
            "\n",
            "Epoch: 210\n",
            "Loss: 0.130 | Acc: 95.512% (47756/50000)\n",
            "Loss: 0.317 | Acc: 90.230% (9023/10000)\n",
            "\n",
            "Epoch: 211\n",
            "Loss: 0.127 | Acc: 95.658% (47829/50000)\n",
            "Loss: 0.301 | Acc: 90.450% (9045/10000)\n",
            "\n",
            "Epoch: 212\n",
            "Loss: 0.122 | Acc: 95.760% (47880/50000)\n",
            "Loss: 0.300 | Acc: 90.770% (9077/10000)\n",
            "\n",
            "Epoch: 213\n",
            "Loss: 0.122 | Acc: 95.808% (47904/50000)\n",
            "Loss: 0.333 | Acc: 89.590% (8959/10000)\n",
            "\n",
            "Epoch: 214\n",
            "Loss: 0.120 | Acc: 95.856% (47928/50000)\n",
            "Loss: 0.275 | Acc: 91.260% (9126/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 215\n",
            "Loss: 0.117 | Acc: 96.040% (48020/50000)\n",
            "Loss: 0.319 | Acc: 90.570% (9057/10000)\n",
            "\n",
            "Epoch: 216\n",
            "Loss: 0.109 | Acc: 96.302% (48151/50000)\n",
            "Loss: 0.293 | Acc: 90.890% (9089/10000)\n",
            "\n",
            "Epoch: 217\n",
            "Loss: 0.105 | Acc: 96.476% (48238/50000)\n",
            "Loss: 0.325 | Acc: 89.880% (8988/10000)\n",
            "\n",
            "Epoch: 218\n",
            "Loss: 0.106 | Acc: 96.388% (48194/50000)\n",
            "Loss: 0.311 | Acc: 90.370% (9037/10000)\n",
            "\n",
            "Epoch: 219\n",
            "Loss: 0.103 | Acc: 96.494% (48247/50000)\n",
            "Loss: 0.290 | Acc: 91.190% (9119/10000)\n",
            "\n",
            "Epoch: 220\n",
            "Loss: 0.097 | Acc: 96.682% (48341/50000)\n",
            "Loss: 0.275 | Acc: 91.420% (9142/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 221\n",
            "Loss: 0.094 | Acc: 96.820% (48410/50000)\n",
            "Loss: 0.288 | Acc: 90.850% (9085/10000)\n",
            "\n",
            "Epoch: 222\n",
            "Loss: 0.094 | Acc: 96.858% (48429/50000)\n",
            "Loss: 0.316 | Acc: 90.600% (9060/10000)\n",
            "\n",
            "Epoch: 223\n",
            "Loss: 0.092 | Acc: 96.966% (48483/50000)\n",
            "Loss: 0.304 | Acc: 90.890% (9089/10000)\n",
            "\n",
            "Epoch: 224\n",
            "Loss: 0.085 | Acc: 97.148% (48574/50000)\n",
            "Loss: 0.274 | Acc: 91.620% (9162/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 225\n",
            "Loss: 0.079 | Acc: 97.364% (48682/50000)\n",
            "Loss: 0.285 | Acc: 91.540% (9154/10000)\n",
            "\n",
            "Epoch: 226\n",
            "Loss: 0.079 | Acc: 97.340% (48670/50000)\n",
            "Loss: 0.272 | Acc: 92.030% (9203/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 227\n",
            "Loss: 0.079 | Acc: 97.334% (48667/50000)\n",
            "Loss: 0.251 | Acc: 92.530% (9253/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 228\n",
            "Loss: 0.076 | Acc: 97.406% (48703/50000)\n",
            "Loss: 0.301 | Acc: 91.390% (9139/10000)\n",
            "\n",
            "Epoch: 229\n",
            "Loss: 0.073 | Acc: 97.476% (48738/50000)\n",
            "Loss: 0.275 | Acc: 92.010% (9201/10000)\n",
            "\n",
            "Epoch: 230\n",
            "Loss: 0.066 | Acc: 97.834% (48917/50000)\n",
            "Loss: 0.284 | Acc: 91.790% (9179/10000)\n",
            "\n",
            "Epoch: 231\n",
            "Loss: 0.070 | Acc: 97.630% (48815/50000)\n",
            "Loss: 0.310 | Acc: 91.030% (9103/10000)\n",
            "\n",
            "Epoch: 232\n",
            "Loss: 0.064 | Acc: 97.800% (48900/50000)\n",
            "Loss: 0.285 | Acc: 91.620% (9162/10000)\n",
            "\n",
            "Epoch: 233\n",
            "Loss: 0.059 | Acc: 98.060% (49030/50000)\n",
            "Loss: 0.297 | Acc: 91.070% (9107/10000)\n",
            "\n",
            "Epoch: 234\n",
            "Loss: 0.054 | Acc: 98.172% (49086/50000)\n",
            "Loss: 0.263 | Acc: 92.480% (9248/10000)\n",
            "\n",
            "Epoch: 235\n",
            "Loss: 0.057 | Acc: 98.110% (49055/50000)\n",
            "Loss: 0.272 | Acc: 92.100% (9210/10000)\n",
            "\n",
            "Epoch: 236\n",
            "Loss: 0.052 | Acc: 98.346% (49173/50000)\n",
            "Loss: 0.266 | Acc: 92.510% (9251/10000)\n",
            "\n",
            "Epoch: 237\n",
            "Loss: 0.046 | Acc: 98.546% (49273/50000)\n",
            "Loss: 0.264 | Acc: 92.330% (9233/10000)\n",
            "\n",
            "Epoch: 238\n",
            "Loss: 0.041 | Acc: 98.704% (49352/50000)\n",
            "Loss: 0.269 | Acc: 92.350% (9235/10000)\n",
            "\n",
            "Epoch: 239\n",
            "Loss: 0.048 | Acc: 98.352% (49176/50000)\n",
            "Loss: 0.289 | Acc: 91.970% (9197/10000)\n",
            "\n",
            "Epoch: 240\n",
            "Loss: 0.044 | Acc: 98.580% (49290/50000)\n",
            "Loss: 0.246 | Acc: 92.900% (9290/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 241\n",
            "Loss: 0.038 | Acc: 98.824% (49412/50000)\n",
            "Loss: 0.253 | Acc: 93.070% (9307/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 242\n",
            "Loss: 0.034 | Acc: 98.898% (49449/50000)\n",
            "Loss: 0.261 | Acc: 93.240% (9324/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 243\n",
            "Loss: 0.029 | Acc: 99.080% (49540/50000)\n",
            "Loss: 0.235 | Acc: 93.550% (9355/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 244\n",
            "Loss: 0.034 | Acc: 98.924% (49462/50000)\n",
            "Loss: 0.242 | Acc: 93.420% (9342/10000)\n",
            "\n",
            "Epoch: 245\n",
            "Loss: 0.029 | Acc: 99.118% (49559/50000)\n",
            "Loss: 0.264 | Acc: 93.130% (9313/10000)\n",
            "\n",
            "Epoch: 246\n",
            "Loss: 0.028 | Acc: 99.086% (49543/50000)\n",
            "Loss: 0.230 | Acc: 93.700% (9370/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 247\n",
            "Loss: 0.023 | Acc: 99.288% (49644/50000)\n",
            "Loss: 0.271 | Acc: 92.870% (9287/10000)\n",
            "\n",
            "Epoch: 248\n",
            "Loss: 0.021 | Acc: 99.328% (49664/50000)\n",
            "Loss: 0.241 | Acc: 93.570% (9357/10000)\n",
            "\n",
            "Epoch: 249\n",
            "Loss: 0.020 | Acc: 99.392% (49696/50000)\n",
            "Loss: 0.245 | Acc: 93.610% (9361/10000)\n",
            "\n",
            "Epoch: 250\n",
            "Loss: 0.020 | Acc: 99.412% (49706/50000)\n",
            "Loss: 0.238 | Acc: 93.640% (9364/10000)\n",
            "\n",
            "Epoch: 251\n",
            "Loss: 0.015 | Acc: 99.584% (49792/50000)\n",
            "Loss: 0.221 | Acc: 94.230% (9423/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 252\n",
            "Loss: 0.012 | Acc: 99.690% (49845/50000)\n",
            "Loss: 0.213 | Acc: 94.170% (9417/10000)\n",
            "\n",
            "Epoch: 253\n",
            "Loss: 0.011 | Acc: 99.720% (49860/50000)\n",
            "Loss: 0.215 | Acc: 94.270% (9427/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 254\n",
            "Loss: 0.009 | Acc: 99.824% (49912/50000)\n",
            "Loss: 0.203 | Acc: 94.500% (9450/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 255\n",
            "Loss: 0.007 | Acc: 99.822% (49911/50000)\n",
            "Loss: 0.224 | Acc: 94.280% (9428/10000)\n",
            "\n",
            "Epoch: 256\n",
            "Loss: 0.009 | Acc: 99.778% (49889/50000)\n",
            "Loss: 0.206 | Acc: 94.540% (9454/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 257\n",
            "Loss: 0.007 | Acc: 99.842% (49921/50000)\n",
            "Loss: 0.210 | Acc: 94.630% (9463/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 258\n",
            "Loss: 0.006 | Acc: 99.864% (49932/50000)\n",
            "Loss: 0.204 | Acc: 94.770% (9477/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 259\n",
            "Loss: 0.005 | Acc: 99.914% (49957/50000)\n",
            "Loss: 0.199 | Acc: 94.940% (9494/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 260\n",
            "Loss: 0.003 | Acc: 99.944% (49972/50000)\n",
            "Loss: 0.199 | Acc: 95.010% (9501/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 261\n",
            "Loss: 0.003 | Acc: 99.962% (49981/50000)\n",
            "Loss: 0.200 | Acc: 94.920% (9492/10000)\n",
            "\n",
            "Epoch: 262\n",
            "Loss: 0.003 | Acc: 99.956% (49978/50000)\n",
            "Loss: 0.192 | Acc: 95.140% (9514/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 263\n",
            "Loss: 0.003 | Acc: 99.966% (49983/50000)\n",
            "Loss: 0.193 | Acc: 95.230% (9523/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 264\n",
            "Loss: 0.003 | Acc: 99.982% (49991/50000)\n",
            "Loss: 0.184 | Acc: 95.280% (9528/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 265\n",
            "Loss: 0.003 | Acc: 99.974% (49987/50000)\n",
            "Loss: 0.182 | Acc: 95.390% (9539/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 266\n",
            "Loss: 0.002 | Acc: 99.974% (49987/50000)\n",
            "Loss: 0.185 | Acc: 95.310% (9531/10000)\n",
            "\n",
            "Epoch: 267\n",
            "Loss: 0.002 | Acc: 99.984% (49992/50000)\n",
            "Loss: 0.183 | Acc: 95.390% (9539/10000)\n",
            "\n",
            "Epoch: 268\n",
            "Loss: 0.002 | Acc: 99.986% (49993/50000)\n",
            "Loss: 0.179 | Acc: 95.330% (9533/10000)\n",
            "\n",
            "Epoch: 269\n",
            "Loss: 0.002 | Acc: 99.986% (49993/50000)\n",
            "Loss: 0.181 | Acc: 95.320% (9532/10000)\n",
            "\n",
            "Epoch: 270\n",
            "Loss: 0.002 | Acc: 99.994% (49997/50000)\n",
            "Loss: 0.179 | Acc: 95.470% (9547/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 271\n",
            "Loss: 0.002 | Acc: 99.998% (49999/50000)\n",
            "Loss: 0.180 | Acc: 95.390% (9539/10000)\n",
            "\n",
            "Epoch: 272\n",
            "Loss: 0.002 | Acc: 99.992% (49996/50000)\n",
            "Loss: 0.177 | Acc: 95.350% (9535/10000)\n",
            "\n",
            "Epoch: 273\n",
            "Loss: 0.002 | Acc: 99.998% (49999/50000)\n",
            "Loss: 0.176 | Acc: 95.490% (9549/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 274\n",
            "Loss: 0.002 | Acc: 99.992% (49996/50000)\n",
            "Loss: 0.178 | Acc: 95.430% (9543/10000)\n",
            "\n",
            "Epoch: 275\n",
            "Loss: 0.002 | Acc: 99.984% (49992/50000)\n",
            "Loss: 0.179 | Acc: 95.450% (9545/10000)\n",
            "\n",
            "Epoch: 276\n",
            "Loss: 0.002 | Acc: 99.996% (49998/50000)\n",
            "Loss: 0.177 | Acc: 95.440% (9544/10000)\n",
            "\n",
            "Epoch: 277\n",
            "Loss: 0.002 | Acc: 99.996% (49998/50000)\n",
            "Loss: 0.178 | Acc: 95.430% (9543/10000)\n",
            "\n",
            "Epoch: 278\n",
            "Loss: 0.002 | Acc: 99.994% (49997/50000)\n",
            "Loss: 0.177 | Acc: 95.460% (9546/10000)\n",
            "\n",
            "Epoch: 279\n",
            "Loss: 0.002 | Acc: 99.998% (49999/50000)\n",
            "Loss: 0.177 | Acc: 95.430% (9543/10000)\n",
            "\n",
            "Epoch: 280\n",
            "Loss: 0.002 | Acc: 99.992% (49996/50000)\n",
            "Loss: 0.176 | Acc: 95.450% (9545/10000)\n",
            "\n",
            "Epoch: 281\n",
            "Loss: 0.002 | Acc: 99.992% (49996/50000)\n",
            "Loss: 0.177 | Acc: 95.460% (9546/10000)\n",
            "\n",
            "Epoch: 282\n",
            "Loss: 0.002 | Acc: 99.996% (49998/50000)\n",
            "Loss: 0.176 | Acc: 95.470% (9547/10000)\n",
            "\n",
            "Epoch: 283\n",
            "Loss: 0.002 | Acc: 99.984% (49992/50000)\n",
            "Loss: 0.176 | Acc: 95.470% (9547/10000)\n",
            "\n",
            "Epoch: 284\n",
            "Loss: 0.002 | Acc: 99.990% (49995/50000)\n",
            "Loss: 0.176 | Acc: 95.490% (9549/10000)\n",
            "\n",
            "Epoch: 285\n",
            "Loss: 0.002 | Acc: 99.994% (49997/50000)\n",
            "Loss: 0.176 | Acc: 95.460% (9546/10000)\n",
            "\n",
            "Epoch: 286\n",
            "Loss: 0.002 | Acc: 99.996% (49998/50000)\n",
            "Loss: 0.175 | Acc: 95.510% (9551/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 287\n",
            "Loss: 0.002 | Acc: 99.992% (49996/50000)\n",
            "Loss: 0.177 | Acc: 95.520% (9552/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 288\n",
            "Loss: 0.002 | Acc: 99.996% (49998/50000)\n",
            "Loss: 0.176 | Acc: 95.510% (9551/10000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoF0t_vDJIoE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "faeb5c16-a325-46e9-be19-8dbaccf14b71"
      },
      "source": [
        "## Save the model after training\n",
        "print('Saving..')\n",
        "state = {\n",
        "    'net': net.state_dict(),\n",
        "    'acc': 95,\n",
        "    'epoch': 289,\n",
        "}\n",
        "if not os.path.isdir('checkpoint'):\n",
        "    os.mkdir('checkpoint')\n",
        "torch.save(state, './checkpoint/poisoned_checkpoint.pth')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving..\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2dzgY_BI3eK"
      },
      "source": [
        "## Testing the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APAL6y75FtLU",
        "outputId": "df9ee571-5972-4c1e-9513-807126aa51e1"
      },
      "source": [
        "# Benign testing\n",
        "\n",
        "net.eval()\n",
        "test_loss = 0\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        outputs = net(inputs)\n",
        "        _, predicted = outputs.max(1)\n",
        "        loss = criterion(outputs, targets)\n",
        "        test_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    print(\"Accuracy/Loss on benign test data: \")\n",
        "    print('Loss: %.3f | Acc: %.3f%% (%d/%d)' % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy/Loss on benign test data: \n",
            "Loss: 0.176 | Acc: 95.510% (9551/10000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJHrKXW-NrRx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86c7f648-62d9-4d90-8ef4-ac4fbc1739a9"
      },
      "source": [
        "# Poisoned testing\n",
        "\n",
        "img_backdoor = Image.open('/tmp/devil.png').resize((6,6))\n",
        "\n",
        "for i in range(0, len(testset.data)):\n",
        "  image = Image.fromarray(testset.data[i])\n",
        "  image.paste(img_backdoor)\n",
        "  testset.data[i] = np.array(image)\n",
        "  testset.targets[i] = 1\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "print(\"Poison Target: \" + classes[1])\n",
        "\n",
        "net.eval()\n",
        "test_loss = 0\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        outputs = net(inputs)\n",
        "        _, predicted = outputs.max(1)\n",
        "\n",
        "        test_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    print(\"Accuracy/Loss on poisoned test data: \")\n",
        "    print('Loss: %.3f | Acc: %.3f%% (%d/%d)' % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Poison Target: car\n",
            "Accuracy/Loss on poisoned test data: \n",
            "Loss: 0.224 | Acc: 100.000% (10000/10000)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}